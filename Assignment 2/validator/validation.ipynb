{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fdbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "# ---------- Load ----------\n",
    "df = pd.read_csv(\"../../porto.csv\")\n",
    "\n",
    "# Parse polyline JSON-like strings -> Python lists of [lon, lat]\n",
    "df[\"POLYLINE\"] = df[\"POLYLINE\"].apply(ast.literal_eval)\n",
    "\n",
    "# ---------- Derive columns to mirror your SQL CHECKs ----------\n",
    "# n_points > 0\n",
    "df[\"n_points\"] = df[\"POLYLINE\"].apply(len)\n",
    "\n",
    "# start_epoch > 0\n",
    "df[\"start_epoch\"] = pd.to_numeric(df[\"TIMESTAMP\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# centroid (domain_middle_lat/lon) from polyline points\n",
    "def centroid_latlon(points):\n",
    "    # points are [lon, lat]; return (lat, lon)\n",
    "    if not points:\n",
    "        return (np.nan, np.nan)\n",
    "    lons = [p[0] for p in points]\n",
    "    lats = [p[1] for p in points]\n",
    "    return (float(np.mean(lats)), float(np.mean(lons)))\n",
    "\n",
    "centroids = df[\"POLYLINE\"].apply(centroid_latlon)\n",
    "df[\"domain_middle_lat\"] = centroids.apply(lambda x: x[0])\n",
    "df[\"domain_middle_lon\"] = centroids.apply(lambda x: x[1])\n",
    "\n",
    "# domain_radius > 0 (meters): max haversine distance from centroid to any point\n",
    "def max_radius_m(points, c_lat, c_lon):\n",
    "    if not points or np.isnan(c_lat) or np.isnan(c_lon):\n",
    "        return np.nan\n",
    "    c = (c_lat, c_lon)  # haversine expects (lat, lon)\n",
    "    mx = 0.0\n",
    "    for lon, lat in points:  # note input order [lon, lat]\n",
    "        d = haversine(c, (lat, lon), unit=Unit.METERS)\n",
    "        if d > mx:\n",
    "            mx = d\n",
    "    return mx\n",
    "\n",
    "df[\"domain_radius\"] = [\n",
    "    max_radius_m(pts, lat, lon)\n",
    "    for pts, lat, lon in zip(df[\"POLYLINE\"], df[\"domain_middle_lat\"], df[\"domain_middle_lon\"])\n",
    "]\n",
    "\n",
    "# ---------- Build boolean masks for the CHECK constraints ----------\n",
    "chk_n_points_positive    = df[\"n_points\"] > 0\n",
    "chk_start_epoch_positive = df[\"start_epoch\"] > 0\n",
    "chk_radius_positive      = df[\"domain_radius\"] > 0\n",
    "chk_latitude_valid       = df[\"domain_middle_lat\"].between(-90, 90, inclusive=\"both\")\n",
    "chk_longitude_valid      = df[\"domain_middle_lon\"].between(-180, 180, inclusive=\"both\")\n",
    "\n",
    "valid_mask = (\n",
    "    chk_n_points_positive\n",
    "    & chk_start_epoch_positive\n",
    "    & chk_radius_positive\n",
    "    & chk_latitude_valid\n",
    "    & chk_longitude_valid\n",
    ")\n",
    "\n",
    "# Optional: see violations\n",
    "# print({\n",
    "#     \"n_points > 0\": (~chk_n_points_positive).sum(),\n",
    "#     \"start_epoch > 0\": (~chk_start_epoch_positive).sum(),\n",
    "#     \"domain_radius > 0\": (~chk_radius_positive).sum(),\n",
    "#     \"-90<=lat<=90\": (~chk_latitude_valid).sum(),\n",
    "#     \"-180<=lon<=180\": (~chk_longitude_valid).sum(),\n",
    "# })\n",
    "\n",
    "# ---------- Cleaned dataframe ----------\n",
    "df_clean = df[valid_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e45eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of taxis: 442\n",
      "Number of trips: 1673953\n",
      "Total GPS points: 83378342\n"
     ]
    }
   ],
   "source": [
    "#Task 1\n",
    "num_taxis = df_clean[\"TAXI_ID\"].nunique()\n",
    "num_trips = len(df_clean)\n",
    "total_gps_points = df_clean[\"n_points\"].sum()\n",
    "\n",
    "print(f\"Number of taxis: {num_taxis}\")\n",
    "print(f\"Number of trips: {num_trips}\")\n",
    "print(f\"Total GPS points: {total_gps_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e0ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average trips per taxi: 3787.22\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "avg_trips_per_taxi = num_trips / num_taxis\n",
    "print(f\"Average trips per taxi: {avg_trips_per_taxi:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd15384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 taxis with most trips:\n",
      "TAXI_ID\n",
      "20000403    7848\n",
      "20000483    7650\n",
      "20000364    7429\n",
      "20000307    7311\n",
      "20000621    7256\n",
      "20000129    7149\n",
      "20000492    7125\n",
      "20000424    7036\n",
      "20000089    7007\n",
      "20000529    6922\n",
      "20000066    6749\n",
      "20000616    6579\n",
      "20000678    6484\n",
      "20000042    6441\n",
      "20000304    6391\n",
      "20000235    6391\n",
      "20000179    6380\n",
      "20000263    6367\n",
      "20000325    6367\n",
      "20000140    6290\n",
      "Name: TRIP_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 3\n",
    "top_taxis = (\n",
    "    df_clean.groupby(\"TAXI_ID\")[\"TRIP_ID\"]\n",
    "    .count()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "print(\"Top 20 taxis with most trips:\")\n",
    "print(top_taxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6346e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAXI_ID\n",
      "20000001    B\n",
      "20000002    B\n",
      "20000003    C\n",
      "20000004    B\n",
      "20000005    B\n",
      "20000006    B\n",
      "20000007    B\n",
      "20000008    B\n",
      "20000009    B\n",
      "20000010    B\n",
      "Name: CALL_TYPE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Task 4a\n",
    "# Most frequent CALL_TYPE per taxi\n",
    "most_used_call_type = (\n",
    "    df_clean.groupby(\"TAXI_ID\")[\"CALL_TYPE\"]\n",
    "    .agg(lambda x: x.value_counts().idxmax())\n",
    ")\n",
    "\n",
    "print(most_used_call_type.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53791001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Average Duration & Distance per CALL_TYPE ===\n",
      "           avg_duration_s  avg_distance_m  num_trips\n",
      "CALL_TYPE                                           \n",
      "A              754.605329     5424.247840     362707\n",
      "B              672.625683     5108.025765     808818\n",
      "C              811.725143     6606.950692     502428\n",
      "\n",
      "=== Share of Trips per Time Band ===\n",
      "time_band               00–06     06–12     12–18     18–24\n",
      "CALL_TYPE CALL_TYPE                                        \n",
      "A         A          0.119256  0.333771  0.321709  0.225264\n",
      "B         B          0.122367  0.301262  0.344804  0.231566\n",
      "C         C          0.329331  0.232666  0.240022  0.197981\n"
     ]
    }
   ],
   "source": [
    "# Task 4b\n",
    "df_clean[\"trip_duration_s\"] = (df_clean[\"n_points\"] - 1) * 15\n",
    "\n",
    "def trip_distance(points):\n",
    "    if len(points) < 2:\n",
    "        return 0.0\n",
    "    dist = 0.0\n",
    "    for i in range(1, len(points)):\n",
    "        lon1, lat1 = points[i-1]\n",
    "        lon2, lat2 = points[i]\n",
    "        dist += haversine((lat1, lon1), (lat2, lon2), unit=Unit.METERS)\n",
    "    return dist\n",
    "\n",
    "df_clean[\"trip_distance_m\"] = df_clean[\"POLYLINE\"].apply(trip_distance)\n",
    "\n",
    "df_clean[\"hour\"] = pd.to_datetime(df_clean[\"TIMESTAMP\"], unit=\"s\").dt.hour\n",
    "\n",
    "def time_band(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return \"00–06\"\n",
    "    elif 6 <= hour < 12:\n",
    "        return \"06–12\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"12–18\"\n",
    "    else:\n",
    "        return \"18–24\"\n",
    "\n",
    "df_clean[\"time_band\"] = df_clean[\"hour\"].apply(time_band)\n",
    "\n",
    "# Average duration and distance per call type\n",
    "avg_stats = df_clean.groupby(\"CALL_TYPE\").agg(\n",
    "    avg_duration_s=(\"trip_duration_s\", \"mean\"),\n",
    "    avg_distance_m=(\"trip_distance_m\", \"mean\"),\n",
    "    num_trips=(\"TRIP_ID\", \"count\")\n",
    ")\n",
    "\n",
    "# Share of trips per time band\n",
    "time_band_share = (\n",
    "    df_clean.groupby([\"CALL_TYPE\", \"time_band\"]).size()\n",
    "    .groupby(level=0)\n",
    "    .apply(lambda x: x / x.sum())  # normalize within each CALL_TYPE\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "print(\"=== Average Duration & Distance per CALL_TYPE ===\")\n",
    "print(avg_stats)\n",
    "\n",
    "print(\"\\n=== Share of Trips per Time Band ===\")\n",
    "print(time_band_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4800effb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top taxis by total hours driven (with total distance):\n",
      "          total_hours  total_distance_km\n",
      "TAXI_ID                                 \n",
      "20000904  1961.079167       62788.703932\n",
      "20000129  1649.758333       36543.724426\n",
      "20000307  1587.091667       40016.545094\n",
      "20000529  1507.295833       42389.150091\n",
      "20000276  1419.883333       47078.202212\n",
      "20000436  1410.687500       44299.741233\n",
      "20000483  1397.708333       36174.843834\n",
      "20000372  1387.133333       40687.944292\n",
      "20000616  1349.133333       35407.607595\n",
      "20000179  1324.283333       39841.171776\n",
      "20000574  1301.925000       37556.280699\n",
      "20000235  1287.879167       36729.592783\n",
      "20000621  1282.433333       31987.930963\n",
      "20000364  1280.491667       41602.180030\n",
      "20000435  1277.575000       40993.150530\n",
      "20000199  1270.791667       39565.220840\n",
      "20000446  1266.633333       35163.690493\n",
      "20000011  1266.120833       38498.321177\n",
      "20000395  1263.800000       34208.191882\n",
      "20000492  1262.566667       33193.583433\n"
     ]
    }
   ],
   "source": [
    "# Task 5\n",
    "# --- Aggregate per taxi ---\n",
    "taxi_usage = df_clean.groupby(\"TAXI_ID\").agg(\n",
    "    total_hours=(\"trip_duration_s\", lambda x: x.sum() / 3600),  # seconds → hours\n",
    "    total_distance_km=(\"trip_distance_m\", lambda x: x.sum() / 1000)  # meters → km\n",
    ")\n",
    "\n",
    "# Sort by total hours (descending)\n",
    "taxi_usage_sorted = taxi_usage.sort_values(by=\"total_hours\", ascending=False)\n",
    "\n",
    "print(\"Top taxis by total hours driven (with total distance):\")\n",
    "print(taxi_usage_sorted.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e1f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trips near City Hall (<=100m): 126340\n",
      "                TRIP_ID   TAXI_ID CALL_TYPE  n_points\n",
      "15  1372637610620000497  20000497         B        64\n",
      "42  1372638361620000154  20000154         C        29\n",
      "48  1372641991620000231  20000231         B        12\n",
      "51  1372636956620000167  20000167         C        32\n",
      "52  1372641197620000653  20000653         B        24\n",
      "58  1372642706620000653  20000653         B        16\n",
      "64  1372636896620000360  20000360         C        43\n",
      "74  1372642071620000305  20000305         C        65\n",
      "80  1372637423620000341  20000341         C        50\n",
      "81  1372639364620000015  20000015         C        42\n"
     ]
    }
   ],
   "source": [
    "# Task 6\n",
    "city_hall = (41.15794, -8.62911)  # (lat, lon)\n",
    "\n",
    "def passes_near_city_hall(points, threshold_m=100):\n",
    "    for lon, lat in points:\n",
    "        d = haversine((lat, lon), city_hall, unit=Unit.METERS)\n",
    "        if d <= threshold_m:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Flag trips that pass within 100 m\n",
    "df_clean[\"near_city_hall\"] = df_clean[\"POLYLINE\"].apply(\n",
    "    lambda pts: passes_near_city_hall(pts, threshold_m=100)\n",
    ")\n",
    "\n",
    "# Extract those trips\n",
    "trips_near_city_hall = df_clean[df_clean[\"near_city_hall\"]]\n",
    "\n",
    "print(f\"Number of trips near City Hall (<=100m): {len(trips_near_city_hall)}\")\n",
    "print(trips_near_city_hall[[\"TRIP_ID\", \"TAXI_ID\", \"CALL_TYPE\", \"n_points\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fcabc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid trips (< 3 GPS points): 7202\n"
     ]
    }
   ],
   "source": [
    "# Invalid trips: fewer than 3 GPS points\n",
    "invalid_trips = df_clean[df_clean[\"n_points\"] < 3]\n",
    "\n",
    "num_invalid_trips = len(invalid_trips)\n",
    "\n",
    "print(f\"Number of invalid trips (< 3 GPS points): {num_invalid_trips}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1751b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique taxi pairs within 5m & 5s at least once: 44998\n",
      "         taxi_a    taxi_b  first_time   last_time  encounters  min_distance_m\n",
      "37798  20000423  20000451  1372638171  1372638171           1        3.019350\n",
      "30849  20000309  20000653  1372640095  1397574241           5        0.753350\n",
      "20258  20000171  20000671  1372649094  1401482847           7        2.001511\n",
      "30533  20000307  20000534  1372649316  1372649316           1        1.505504\n",
      "37032  20000398  20000540  1372649899  1395655386           4        1.807443\n",
      "19988  20000167  20000403  1372653680  1401801227           5        0.000000\n",
      "15974  20000128  20000154  1372653763  1402511283           2        3.175811\n",
      "31945  20000325  20000571  1372655214  1402808434           2        2.504273\n",
      "26200  20000247  20000514  1372656391  1400574563           3        1.809050\n",
      "43101  20000561  20000570  1372656721  1372656751           3        1.507145\n",
      "33035  20000337  20000539  1372657141  1373015256           3        3.014654\n",
      "4480   20000024  20000242  1372659199  1399693943           3        1.807615\n",
      "16029  20000128  20000400  1372660432  1383069529          11        0.753365\n",
      "23655  20000207  20000480  1372660600  1372660855           2        1.807443\n",
      "7646   20000049  20000294  1372662360  1396862688           7        1.000756\n",
      "6696   20000042  20000267  1372663476  1399489275           3        1.000756\n",
      "20932  20000178  20000496  1372663780  1373019963           5        1.507222\n",
      "17633  20000144  20000562  1372664498  1393677863           7        1.252770\n",
      "37472  20000409  20000562  1372664724  1403250592           8        1.000756\n",
      "42471  20000534  20000651  1372664764  1372664764           1        3.012992\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from haversine import haversine, Unit\n",
    "from math import cos, radians\n",
    "\n",
    "# --- Parameters ---\n",
    "TIME_WINDOW_S = 5\n",
    "DIST_THRESH_M = 5.0\n",
    "\n",
    "# --- 1) Explode trips into per-point pings with absolute timestamps ---\n",
    "#    Each point i occurs at TIMESTAMP + 15*i (Porto dataset sampling)\n",
    "def explode_points(df):\n",
    "    records = []\n",
    "    for row in df.itertuples(index=False):\n",
    "        start = int(row.TIMESTAMP)\n",
    "        taxi  = row.TAXI_ID\n",
    "        pts   = row.POLYLINE  # list of [lon, lat]\n",
    "        for i, (lon, lat) in enumerate(pts):\n",
    "            t = start + 15*i\n",
    "            records.append((t, taxi, lat, lon))\n",
    "    return pd.DataFrame(records, columns=[\"time\", \"taxi_id\", \"lat\", \"lon\"])\n",
    "\n",
    "pings = explode_points(df_clean)\n",
    "# Keep only pings from trips with at least 1 point (df_clean already enforces >0 and > radius)\n",
    "pings = pings.dropna(subset=[\"time\", \"taxi_id\", \"lat\", \"lon\"]).astype({\"time\":\"int64\"})\n",
    "pings.sort_values(\"time\", inplace=True, ignore_index=True)\n",
    "\n",
    "# --- 2) Sliding time window over sorted pings ---\n",
    "# Keep a deque of points within the last TIME_WINDOW_S\n",
    "# Use a quick bounding box prefilter to avoid many haversine calls.\n",
    "# At Porto's latitude (~41°), 1° lat ~ 111,320 m; 1° lon ~ 111,320*cos(lat) ≈ 84,000 m.\n",
    "LAT_DEG_PER_M = 1.0 / 111_320.0\n",
    "def lon_deg_per_m_at(lat):\n",
    "    return 1.0 / (111_320.0 * max(0.1, cos(radians(lat))))  # guard cos->0 near poles (not needed here but safe)\n",
    "\n",
    "window = deque()  # items: (time, taxi_id, lat, lon)\n",
    "encounters = []   # (taxi_a, taxi_b, time, distance_m)\n",
    "\n",
    "for row in pings.itertuples(index=False):\n",
    "    t, taxi, lat, lon = row.time, row.taxi_id, row.lat, row.lon\n",
    "\n",
    "    # evict old points\n",
    "    while window and (t - window[0][0]) > TIME_WINDOW_S:\n",
    "        window.popleft()\n",
    "\n",
    "    # precompute lon degree threshold at current latitude\n",
    "    lat_eps = DIST_THRESH_M * LAT_DEG_PER_M\n",
    "    lon_eps = DIST_THRESH_M * lon_deg_per_m_at(lat)\n",
    "\n",
    "    # compare to points in the window\n",
    "    for t2, taxi2, lat2, lon2 in window:\n",
    "        if taxi2 == taxi:\n",
    "            continue\n",
    "        # cheap prefilter: bounding box within ~5m\n",
    "        if abs(lat - lat2) <= lat_eps and abs(lon - lon2) <= lon_eps:\n",
    "            d = haversine((lat, lon), (lat2, lon2), unit=Unit.METERS)\n",
    "            if d <= DIST_THRESH_M:\n",
    "                a, b = (taxi, taxi2) if taxi < taxi2 else (taxi2, taxi)\n",
    "                encounters.append((a, b, min(t, t2), d))\n",
    "\n",
    "    # add current point to window\n",
    "    window.append((t, taxi, lat, lon))\n",
    "\n",
    "# --- 3) Aggregate to unique taxi pairs that met the criteria at least once ---\n",
    "if encounters:\n",
    "    enc_df = pd.DataFrame(encounters, columns=[\"taxi_a\", \"taxi_b\", \"time\", \"distance_m\"])\n",
    "\n",
    "    pairs = (\n",
    "        enc_df.groupby([\"taxi_a\", \"taxi_b\"])\n",
    "        .agg(\n",
    "            first_time=(\"time\", \"min\"),\n",
    "            last_time=(\"time\", \"max\"),\n",
    "            encounters=(\"time\", \"count\"),\n",
    "            min_distance_m=(\"distance_m\", \"min\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values([\"first_time\", \"taxi_a\", \"taxi_b\"], ascending=[True, True, True])\n",
    "    )\n",
    "\n",
    "    print(f\"Unique taxi pairs within 5m & 5s at least once: {len(pairs)}\")\n",
    "    print(pairs.head(20))  # show a sample\n",
    "else:\n",
    "    print(\"No pairs found within 5 meters and 5 seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db23d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midnight-crossing trips: 8029\n",
      "                  TRIP_ID   TAXI_ID CALL_TYPE   TIMESTAMP  n_points  \\\n",
      "4236  1372718798620000370  20000370         A  1372718798        62   \n",
      "4266  1372719200620000031  20000031         B  1372719200        54   \n",
      "4288  1372719157620000632  20000632         B  1372719157        33   \n",
      "4307  1372719271620000503  20000503         B  1372719271        35   \n",
      "4322  1372719469620000409  20000409         B  1372719469        19   \n",
      "4341  1372719230620000406  20000406         A  1372719230        59   \n",
      "4344  1372719093620000022  20000022         B  1372719093        43   \n",
      "4358  1372719315620000008  20000008         B  1372719315        41   \n",
      "4364  1372718162620000560  20000560         C  1372718162       105   \n",
      "4399  1372719396620000304  20000304         C  1372719396        69   \n",
      "4407  1372719050620000596  20000596         B  1372719050        60   \n",
      "4781  1372719317620000101  20000101         C  1372719317        69   \n",
      "5525  1372717190620000388  20000388         A  1372717190       180   \n",
      "6442  1372719098620000509  20000509         A  1372719098        41   \n",
      "8845  1372805454620000307  20000307         C  1372805454        39   \n",
      "8866  1372805705620000596  20000596         A  1372805705        47   \n",
      "8886  1372804573620000665  20000665         A  1372804573       243   \n",
      "8889  1372805480620000671  20000671         C  1372805480        96   \n",
      "8890  1372805426620000514  20000514         B  1372805426        60   \n",
      "8917  1372805751620000684  20000684         C  1372805751       114   \n",
      "\n",
      "       end_epoch               start_local                 end_local  \\\n",
      "4236  1372719713 2013-07-01 23:46:38+01:00 2013-07-02 00:01:53+01:00   \n",
      "4266  1372719995 2013-07-01 23:53:20+01:00 2013-07-02 00:06:35+01:00   \n",
      "4288  1372719637 2013-07-01 23:52:37+01:00 2013-07-02 00:00:37+01:00   \n",
      "4307  1372719781 2013-07-01 23:54:31+01:00 2013-07-02 00:03:01+01:00   \n",
      "4322  1372719739 2013-07-01 23:57:49+01:00 2013-07-02 00:02:19+01:00   \n",
      "4341  1372720100 2013-07-01 23:53:50+01:00 2013-07-02 00:08:20+01:00   \n",
      "4344  1372719723 2013-07-01 23:51:33+01:00 2013-07-02 00:02:03+01:00   \n",
      "4358  1372719915 2013-07-01 23:55:15+01:00 2013-07-02 00:05:15+01:00   \n",
      "4364  1372719722 2013-07-01 23:36:02+01:00 2013-07-02 00:02:02+01:00   \n",
      "4399  1372720416 2013-07-01 23:56:36+01:00 2013-07-02 00:13:36+01:00   \n",
      "4407  1372719935 2013-07-01 23:50:50+01:00 2013-07-02 00:05:35+01:00   \n",
      "4781  1372720337 2013-07-01 23:55:17+01:00 2013-07-02 00:12:17+01:00   \n",
      "5525  1372719875 2013-07-01 23:19:50+01:00 2013-07-02 00:04:35+01:00   \n",
      "6442  1372719698 2013-07-01 23:51:38+01:00 2013-07-02 00:01:38+01:00   \n",
      "8845  1372806024 2013-07-02 23:50:54+01:00 2013-07-03 00:00:24+01:00   \n",
      "8866  1372806395 2013-07-02 23:55:05+01:00 2013-07-03 00:06:35+01:00   \n",
      "8886  1372808203 2013-07-02 23:36:13+01:00 2013-07-03 00:36:43+01:00   \n",
      "8889  1372806905 2013-07-02 23:51:20+01:00 2013-07-03 00:15:05+01:00   \n",
      "8890  1372806311 2013-07-02 23:50:26+01:00 2013-07-03 00:05:11+01:00   \n",
      "8917  1372807446 2013-07-02 23:55:51+01:00 2013-07-03 00:24:06+01:00   \n",
      "\n",
      "      duration_s  \n",
      "4236         915  \n",
      "4266         795  \n",
      "4288         480  \n",
      "4307         510  \n",
      "4322         270  \n",
      "4341         870  \n",
      "4344         630  \n",
      "4358         600  \n",
      "4364        1560  \n",
      "4399        1020  \n",
      "4407         885  \n",
      "4781        1020  \n",
      "5525        2685  \n",
      "6442         600  \n",
      "8845         570  \n",
      "8866         690  \n",
      "8886        3630  \n",
      "8889        1425  \n",
      "8890         885  \n",
      "8917        1695  \n"
     ]
    }
   ],
   "source": [
    "# If you already have df_clean with parsed POLYLINE and n_points, you can skip the prep block.\n",
    "df_use = df_clean.copy() if 'df_clean' in globals() else pd.read_csv(\"../../porto.csv\")\n",
    "if 'POLYLINE' in df_use.columns and df_use['POLYLINE'].dtype == object and not isinstance(df_use['POLYLINE'].iloc[0], list):\n",
    "    df_use['POLYLINE'] = df_use['POLYLINE'].apply(ast.literal_eval)\n",
    "if 'n_points' not in df_use.columns:\n",
    "    df_use['n_points'] = df_use['POLYLINE'].apply(len)\n",
    "\n",
    "# Start/end timestamps (seconds since epoch). Porto dataset uses 15s spacing between points.\n",
    "df_use['end_epoch'] = df_use['TIMESTAMP'] + (df_use['n_points'] - 1) * 15\n",
    "\n",
    "# Convert to local Porto time for calendar-day comparison\n",
    "start_dt = pd.to_datetime(df_use['TIMESTAMP'], unit='s', utc=True).dt.tz_convert('Europe/Lisbon')\n",
    "end_dt   = pd.to_datetime(df_use['end_epoch'], unit='s', utc=True).dt.tz_convert('Europe/Lisbon')\n",
    "\n",
    "# Midnight crosser: started on one date, ended on a different date\n",
    "midnight_mask = start_dt.dt.date != end_dt.dt.date\n",
    "\n",
    "midnight_crossers = df_use.loc[midnight_mask, [\n",
    "    'TRIP_ID', 'TAXI_ID', 'CALL_TYPE', 'TIMESTAMP', 'n_points', 'end_epoch'\n",
    "]].copy()\n",
    "midnight_crossers['start_local'] = start_dt[midnight_mask]\n",
    "midnight_crossers['end_local']   = end_dt[midnight_mask]\n",
    "midnight_crossers['duration_s']  = (midnight_crossers['end_epoch'] - midnight_crossers['TIMESTAMP']).astype('int64')\n",
    "\n",
    "print(f\"Midnight-crossing trips: {len(midnight_crossers)}\")\n",
    "print(midnight_crossers.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5990f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circular trips (start/end ≤ 50 m): 25386\n",
      "                     TRIP_ID   TAXI_ID CALL_TYPE  n_points  start_end_dist_m\n",
      "1489162  1400391940620000492  20000492         C         4               0.0\n",
      "765005   1386858221620000172  20000172         C         3               0.0\n",
      "1529634  1401118088620000066  20000066         C         3               0.0\n",
      "1309482  1397251581620000060  20000060         A        68               0.0\n",
      "1498168  1400576225620000525  20000525         C        99               0.0\n",
      "508386   1382110717620000099  20000099         C         6               0.0\n",
      "269858   1377966324620000372  20000372         A        77               0.0\n",
      "1623940  1402682991620000565  20000565         B         4               0.0\n",
      "1064643  1392644995620000448  20000448         C         3               0.0\n",
      "1011846  1391674467620000596  20000596         A        37               0.0\n",
      "735851   1386331208620000032  20000032         B         3               0.0\n",
      "316555   1378891786620000303  20000303         C         4               0.0\n",
      "309898   1378757569620000648  20000648         B         4               0.0\n",
      "605172   1383836028620000058  20000058         B         4               0.0\n",
      "427937   1380739344620000167  20000167         A         5               0.0\n",
      "851728   1388422686620000198  20000198         B        10               0.0\n",
      "1030033  1391973815620000137  20000137         A        12               0.0\n",
      "921324   1389790258620000304  20000304         B         6               0.0\n",
      "645922   1384611977620000007  20000007         B         4               0.0\n",
      "108483   1374602787620000400  20000400         C         5               0.0\n"
     ]
    }
   ],
   "source": [
    "# Require at least two points to compare start/end\n",
    "mask_ge2 = df_clean[\"n_points\"] >= 2\n",
    "\n",
    "# Extract start/end (lat, lon) from POLYLINE\n",
    "def start_latlon(pts):\n",
    "    lon, lat = pts[0]\n",
    "    return lat, lon\n",
    "\n",
    "def end_latlon(pts):\n",
    "    lon, lat = pts[-1]\n",
    "    return lat, lon\n",
    "\n",
    "df_use = df_clean[mask_ge2].copy()\n",
    "df_use[\"start_latlon\"] = df_use[\"POLYLINE\"].apply(start_latlon)\n",
    "df_use[\"end_latlon\"]   = df_use[\"POLYLINE\"].apply(end_latlon)\n",
    "\n",
    "# Haversine distance (meters) between start and end\n",
    "df_use[\"start_end_dist_m\"] = df_use.apply(\n",
    "    lambda r: haversine(r[\"start_latlon\"], r[\"end_latlon\"], unit=Unit.METERS),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Circular trips: start/end within 50 m\n",
    "circular_mask = df_use[\"start_end_dist_m\"] <= 50.0\n",
    "circular_trips = df_use.loc[circular_mask, [\n",
    "    \"TRIP_ID\", \"TAXI_ID\", \"CALL_TYPE\", \"n_points\", \"start_end_dist_m\"\n",
    "]].sort_values(\"start_end_dist_m\")\n",
    "\n",
    "print(f\"Circular trips (start/end ≤ 50 m): {len(circular_trips)}\")\n",
    "print(circular_trips.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c1871c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 taxis with highest average idle time (hours):\n",
      "TAXI_ID\n",
      "20000941    1746.613519\n",
      "20000969     233.437701\n",
      "20000312      13.070253\n",
      "20000510      12.813855\n",
      "20000609      11.835517\n",
      "20000579      11.384354\n",
      "20000079       9.603897\n",
      "20000072       9.108515\n",
      "20000185       9.008618\n",
      "20000449       8.857682\n",
      "20000902       7.532595\n",
      "20000170       6.733472\n",
      "20000535       6.625844\n",
      "20000315       6.445517\n",
      "20000071       6.240770\n",
      "20000225       6.216521\n",
      "20000545       5.911245\n",
      "20000407       5.630359\n",
      "20000205       5.564613\n",
      "20000443       5.411748\n",
      "Name: idle_time_s, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute trip end time (epoch seconds)\n",
    "df_clean[\"end_epoch\"] = df_clean[\"TIMESTAMP\"] + (df_clean[\"n_points\"] - 1) * 15\n",
    "\n",
    "# Sort trips per taxi chronologically\n",
    "df_sorted = df_clean.sort_values([\"TAXI_ID\", \"TIMESTAMP\"]).copy()\n",
    "\n",
    "# Shift start times to align consecutive trips\n",
    "df_sorted[\"next_start\"] = df_sorted.groupby(\"TAXI_ID\")[\"TIMESTAMP\"].shift(-1)\n",
    "\n",
    "# Idle time = next trip start - current trip end\n",
    "df_sorted[\"idle_time_s\"] = df_sorted[\"next_start\"] - df_sorted[\"end_epoch\"]\n",
    "\n",
    "# Keep only positive idle times (ignore overlaps / errors)\n",
    "df_sorted = df_sorted[df_sorted[\"idle_time_s\"] > 0]\n",
    "\n",
    "# Average idle time per taxi (in hours for readability)\n",
    "avg_idle = (\n",
    "    df_sorted.groupby(\"TAXI_ID\")[\"idle_time_s\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20) / 3600  # convert seconds → hours\n",
    ")\n",
    "\n",
    "print(\"Top 20 taxis with highest average idle time (hours):\")\n",
    "print(avg_idle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50abde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databaseenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
