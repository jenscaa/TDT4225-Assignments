{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23bb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_small = pd.read_csv('../data/links_small.csv')\n",
    "links_small.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('../data/links.csv')\n",
    "links.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unique ID sets\n",
    "# small_idx = pd.Index(links_small['movieId'].dropna().unique())\n",
    "# full_idx  = pd.Index(links['movieId'].dropna().unique())\n",
    "\n",
    "small_idx = pd.Index(links_small['imdbId'].dropna().unique())\n",
    "full_idx  = pd.Index(links['imdbId'].dropna().unique())\n",
    "\n",
    "small_idx = pd.Index(links_small['tmdbId'].dropna().unique())\n",
    "full_idx  = pd.Index(links['tmdbId'].dropna().unique())\n",
    "\n",
    "# IDs in small but not in full\n",
    "only_in_small = small_idx.difference(full_idx)\n",
    "# IDs in full but not in small\n",
    "only_in_full  = full_idx.difference(small_idx)\n",
    "\n",
    "print(f\"Only in small (count {len(only_in_small)}):\", only_in_small.to_list()[:20], \"...\")\n",
    "print(f\"Only in full  (count {len(only_in_full)}):\",  only_in_full.to_list()[:20],  \"...\")\n",
    "\n",
    "# If you want NumPy arrays instead:\n",
    "missing_from_full  = np.setdiff1d(small_idx.values, full_idx.values)\n",
    "missing_from_small = np.setdiff1d(full_idx.values, small_idx.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _normalize_links(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # keep only the id columns that exist\n",
    "    keep = [c for c in ['movieId', 'imdbId', 'tmdbId'] if c in df.columns]\n",
    "    df = df[keep]\n",
    "\n",
    "    # to numeric, allow NA; use pandas nullable Int64 (keeps NaN)\n",
    "    for c in keep:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce').astype('Int64')\n",
    "\n",
    "    # drop exact duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def merge_links(links: pd.DataFrame, links_small: pd.DataFrame):\n",
    "    full  = _normalize_links(links)\n",
    "    small = _normalize_links(links_small)\n",
    "\n",
    "    # quick uniqueness diagnostics\n",
    "    diag = {\n",
    "        'movieId_only_in_small': len(pd.Index(small['movieId'].dropna().unique()).difference(pd.Index(full['movieId'].dropna().unique()))),\n",
    "        'movieId_only_in_full' : len(pd.Index(full['movieId'].dropna().unique()).difference(pd.Index(small['movieId'].dropna().unique()))),\n",
    "        'imdb_only_in_small'   : len(pd.Index(small['imdbId'].dropna().unique()).difference(pd.Index(full['imdbId'].dropna().unique()))),\n",
    "        'imdb_only_in_full'    : len(pd.Index(full['imdbId'].dropna().unique()).difference(pd.Index(small['imdbId'].dropna().unique()))),\n",
    "        'tmdb_only_in_small'   : len(pd.Index(small['tmdbId'].dropna().unique()).difference(pd.Index(full['tmdbId'].dropna().unique()))),\n",
    "        'tmdb_only_in_full'    : len(pd.Index(full['tmdbId'].dropna().unique()).difference(pd.Index(small['tmdbId'].dropna().unique()))),\n",
    "    }\n",
    "\n",
    "    merged = full.merge(\n",
    "        small, how='outer', on='movieId', suffixes=('_full', '_small'), indicator=True\n",
    "    )\n",
    "\n",
    "    # conflicts (both present and different)\n",
    "    for col in ['imdbId', 'tmdbId']:\n",
    "        merged[f'{col}_conflict'] = (\n",
    "            merged[f'{col}_full'].notna() &\n",
    "            merged[f'{col}_small'].notna() &\n",
    "            (merged[f'{col}_full'] != merged[f'{col}_small'])\n",
    "        )\n",
    "\n",
    "    # resolved columns: prefer FULL, else take SMALL\n",
    "    merged['imdbId_resolved'] = merged['imdbId_full'].combine_first(merged['imdbId_small'])\n",
    "    merged['tmdbId_resolved'] = merged['tmdbId_full'].combine_first(merged['tmdbId_small'])\n",
    "\n",
    "    # provenance & final shape\n",
    "    merged['source'] = merged['_merge'].map({'left_only':'full', 'right_only':'small', 'both':'both'})\n",
    "    conflicts = merged[(merged['imdbId_conflict']) | (merged['tmdbId_conflict'])].copy()\n",
    "\n",
    "    final = (\n",
    "        merged[['movieId', 'imdbId_resolved', 'tmdbId_resolved', 'source']]\n",
    "        .rename(columns={'imdbId_resolved':'imdbId', 'tmdbId_resolved':'tmdbId'})\n",
    "        .sort_values('movieId')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # optional: create zero-padded IMDb tt-ids for APIs (keep original int columns as-is)\n",
    "    # final['imdb_tt'] = final['imdbId'].apply(lambda x: f\"tt{int(x):07d}\" if pd.notna(x) else pd.NA)\n",
    "\n",
    "    # sanity checks: after merging, the union should be covered\n",
    "    # assert set(final['movieId'].dropna()) == set(full['movieId'].dropna()).union(set(small['movieId'].dropna()))\n",
    "\n",
    "    return final, conflicts, diag\n",
    "\n",
    "# ===== run it =====\n",
    "final_links, id_conflicts, diagnostics = merge_links(links, links_small)\n",
    "\n",
    "print(\"Diagnostics:\", diagnostics)\n",
    "print(\"Final rows:\", len(final_links))\n",
    "print(\"Conflicts (rows where small vs full disagree on imdb/tmdb):\", len(id_conflicts))\n",
    "print(id_conflicts[['movieId','imdbId_full','imdbId_small','tmdbId_full','tmdbId_small']].head(10))\n",
    "\n",
    "# Save if you want:\n",
    "final_links.to_csv(\"links_merged.csv\", index=False)\n",
    "\n",
    "links_merged = pd.read_csv(\"links_merged.csv\")\n",
    "links_merged.info()\n",
    "# id_conflicts.to_csv(\"links_id_conflicts_for_review.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
